<!DOCTYPE html>
<html lang="en-US" dir="ltr">
<head>
	<title>Web Config Robots</title>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">
	<meta name="description" content="Web Config Robots - Visual editor for robots.txt files">
	<meta name="view-transition" content="same-origin">
	<link rel="stylesheet" href="/ui/base/base.css">
	<script type="importmap">
		{
			"imports": {
				"@browser.style/web-config-shared": "../web-config-shared/index.js"
			}
		}
	</script>
</head>
<body>
	<h1>Web Config: robots.txt</h1>
	<p>
		A visual editor for managing <code>robots.txt</code> files with support for allow/disallow rules, crawl-delay and more.
		See the <a href="/ui/web-config-robots/demo.html">demo page</a> for an example with a robots.txt file loaded.
	</p>
	<web-config-robots></web-config-robots>
	<script type="module" src="./src/index.js"></script>
</body>
</html>
